# ── Anthropic（デフォルト） ──────────────────────────────
ANTHROPIC_API_KEY=your-anthropic-api-key
MODEL_LARGE=anthropic/claude-sonnet-4-5-20250929
MODEL_SMALL=anthropic/claude-haiku-4-5-20251001

# ── OpenAI（切り替える場合はコメントを外し、Anthropicをコメントアウト） ──
# OPENAI_API_KEY=your-openai-api-key
# MODEL_LARGE=openai/gpt-4o
# MODEL_SMALL=openai/gpt-4o-mini

# ── Google Gemini（切り替える場合はコメントを外し、Anthropicをコメントアウト） ──
# GOOGLE_API_KEY=your-google-api-key
# MODEL_LARGE=gemini/gemini-2.0-flash
# MODEL_SMALL=gemini/gemini-2.0-flash

# ── Ollama・ローカルLLM（APIキー不要・完全無料） ──────────
# 事前準備: Ollama をインストールして対象モデルを pull しておくこと
#   https://ollama.com
#   ollama pull qwen3:4b
# Ollama アプリを起動した状態で crewai run を実行する。
# APIキーは不要。Ollamaが localhost:11434 で OpenAI 互換 API を提供する。
# ※ 出力品質はクラウドモデルより低くなる場合があります。
# MODEL_LARGE=ollama/qwen3:4b
# MODEL_SMALL=ollama/qwen3:4b
# （crew.py が ollama/ プレフィックスを検出し、自動で localhost に接続します）

# ── その他 ──────────────────────────────────────────────
STITCH_API_KEY=your-stitch-api-key
